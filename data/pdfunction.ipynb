{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "#AGB(coniferous tree)\n",
    "def bio_C(D):\n",
    "    bio = 1.031 * math.exp(-1.51+1.157*math.log(D)+0.518*(math.log(D))**2-0.067*(math.log(D))**3)\n",
    "    return bio\n",
    "\n",
    "#AGB(deciduous broadleaf tree)\n",
    "def bio_DA(D):\n",
    "    bio = 1.031 * math.exp(-1.501+1.375*math.log(D)+0.464*(math.log(D))**2-0.061*(math.log(D))**3)\n",
    "    return bio\n",
    "\n",
    "#AGB(evergreen broadleaf tree)\n",
    "def bio_EA(D):\n",
    "    bio = 1.031 * math.exp(-1.698+1.851*math.log(D)+0.239*(math.log(D))**2-0.031*(math.log(D))**3)\n",
    "    return bio    \n",
    "\n",
    "#AGB(density known)\n",
    "def bio_dense(D,dense):\n",
    "    bio = 1.029 * math.exp(-1.196+1.622*math.log(D)+0.338*(math.log(D))**2-0.044*(math.log(D))**3+0.708*math.log(dense))\n",
    "    return bio\n",
    "\n",
    "\n",
    "#measuring biomass. measure == \"B\" if you want to measure biomass. measure == \"C\" if you want to measure carbon stock.（default is \"C\".）\n",
    "#x is a pandas series that has \"DBH\",\"Wood density (g/cm3)\",\"type\" keys.\n",
    "def measurebio(x,measure=\"C\",ignore=False):\n",
    "    if x[\"Wood density (g/cm3)\"] ==2:\n",
    "        biomass = bio_C(x[\"DBH\"])/1000\n",
    "    elif x[\"Wood density (g/cm3)\"] == 3:\n",
    "        biomass = bio_DA(x[\"DBH\"])/1000\n",
    "    elif x[\"Wood density (g/cm3)\"] == 4:\n",
    "        biomass = bio_EA(x[\"DBH\"])/1000\n",
    "    elif x[\"Wood density (g/cm3)\"] < 2:\n",
    "        biomass = bio_dense(x[\"DBH\"],x[\"Wood density (g/cm3)\"])/1000\n",
    "    else:\n",
    "        if not ignore:\n",
    "            raise parameter_Error(\"Wood density is invalid\")\n",
    "\n",
    "    if measure == \"C\":\n",
    "        if x[\"type\"] == 'EB' or x[\"type\"]=='DB':\n",
    "            biomass = biomass * 0.48\n",
    "        elif x[\"type\"]=='EC':\n",
    "            biomass = biomass * 0.51\n",
    "        else:\n",
    "            raise parameter_Error(\"You must specify type as EB,DB or EC\")\n",
    "    else:\n",
    "        if not ignore:\n",
    "            raise parameter_Error(\"measure parameter is invalid\")\n",
    "    return biomass\n",
    "\n",
    "#dominant species\n",
    "def max_species(frame,co):\n",
    "    data = frame.sort_values(co,ascending=False)\n",
    "    top1 = data.iloc[0][\"species\"]\n",
    "    if len(data) == 2:\n",
    "        top2=data.iloc[1][\"species\"]\n",
    "        top3=None\n",
    "    elif len(data)==1:\n",
    "        top2=top3=None\n",
    "    else:\n",
    "        top2=data.iloc[1][\"species\"]\n",
    "        top3=data.iloc[2][\"species\"]\n",
    "    return top1,top2,top3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate dominant species, biomass and taxonomic diversity (make filelist)\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "#df[[\"species\",\"type\",\"region\"]]=df[[\"species\",\"type\",\"region\"]].astype(\"string\")\n",
    "class parameter_Error(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "#read inventory data\n",
    "df=pd.read_csv(\"./inventory_current.csv\",index_col=0)\n",
    "\n",
    "flist = df.groupby(\"ID\")[\"forest_type\"].unique().reset_index().set_axis([\"ID\",\"forest_type\"],axis=1)\n",
    "\n",
    "df[\"bio\"] = df[[\"DBH\",\"Wood density (g/cm3)\",\"type\"]].apply(measurebio,measure=\"C\",axis=1)\n",
    "df[\"bio\"]=df[[\"DBH\",\"bio\"]].apply(lambda x: x[\"bio\"]*2.5 if x[\"DBH\"]<18 else x[\"bio\"], axis=1)\n",
    "\n",
    "a = df.groupby([\"ID\",\"species\"])['bio'].agg([(\"biomass\",\"sum\"),(\"counts_s\",\"count\")]).reset_index()\n",
    "\n",
    "type_df = df.groupby([\"ID\",\"type\"])['bio'].sum().unstack().reset_index()\n",
    "type_df[[\"EB\",\"DB\",\"EC\"]]=type_df[[\"EB\",\"DB\",\"EC\"]].fillna(0)\n",
    "type_df[\"allC\"] = type_df[\"EB\"]+type_df[\"DB\"]+type_df[\"EC\"]\n",
    "y=df.groupby([\"ID\"])[\"DBH\"].agg([(\"min_DBH\",\"min\"),(\"max_DBH\",\"max\"),(\"counts\",\"count\")])\n",
    "z=df.groupby([\"ID\"])[\"species\"].nunique()\n",
    "\n",
    "type_df=pd.merge(type_df,y,on=\"ID\")\n",
    "type_df=pd.merge(type_df,z,on=\"ID\")\n",
    "\n",
    "b = a.groupby(\"ID\").apply(max_species,co = \"counts_s\").reset_index().set_axis([\"ID\",\"dominant_c\"],axis=1)\n",
    "c = b[\"dominant_c\"].apply(pd.Series).set_axis([f\"dominant_c{i}\" for i in range(1,4)],axis=1)\n",
    "c[\"ID\"]=b[\"ID\"]\n",
    "\n",
    "d = a.groupby(\"ID\").apply(max_species,co = \"biomass\").reset_index().set_axis([\"ID\",\"dominant_b\"],axis=1)\n",
    "e = d[\"dominant_b\"].apply(pd.Series).set_axis([f\"dominant_b{i}\" for i in range(1,4)],axis=1)\n",
    "e[\"ID\"]=d[\"ID\"]\n",
    "\n",
    "b=pd.merge(b,c,on=\"ID\").drop(\"dominant_c\",axis=1)\n",
    "b=pd.merge(b,e,on=\"ID\")\n",
    "\n",
    "merged=pd.merge(flist,b,on=\"ID\")\n",
    "merged=pd.merge(merged,type_df,on=\"ID\")\n",
    "\n",
    "#area of current plots is 0.1ha.\n",
    "#merged[\"area\"]=0.1\n",
    "merged[\"EB\"]=merged[\"EB\"]/merged[\"area\"]\n",
    "merged[\"DB\"]=merged[\"DB\"]/merged[\"area\"]\n",
    "merged[\"EC\"]=merged[\"EC\"]/merged[\"area\"]\n",
    "merged[\"allC\"]=merged[\"allC\"]/merged[\"area\"]\n",
    "\n",
    "#merged is filelist of inventory data\n",
    "#in historical data, K057, S158 and S180 are removed because their minimum DBH calss are not 10cm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dominant species table (TableS1)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "Past = pd.read_csv(\"./inventory_historical.csv\")\n",
    "present = pd.read_csv(\"./inventory_current.csv\")\n",
    "Natural = present[present[\"forest_type\"]==\"natural\"]\n",
    "Df = pd.read_csv(\"./filelist_historical.csv\")\n",
    "\n",
    "past,natural,df = Past.copy(),Natural.copy(),Df.copy()\n",
    "\n",
    "#select region (shikoku or kyushu)\n",
    "region=\"kyushu\"\n",
    "\n",
    "df = df[df[\"region\"]== region]\n",
    "past = past[past[\"region\"]== region]\n",
    "natural = natural[natural[\"region\"]== region]\n",
    "\n",
    "natural = natural[[\"ID\",\"species\",\"DBH\"]]\n",
    "natural_area = round(natural[\"ID\"].nunique()*0.1,2)\n",
    "\n",
    "#measure basal area (m2/ha) and density (individuals/ha)\n",
    "past[\"BA\"] = (past[\"DBH\"]/2)**2*math.pi/10000\n",
    "natural[\"BA\"] =  natural.apply(lambda x :((x[\"DBH\"]/2)**2*math.pi)/10000 if x[\"DBH\"]>=18 else ((x[\"DBH\"]/2)**2*math.pi)/4000,axis=1)\n",
    "\n",
    "natural[\"count\"] = natural.apply(lambda x : 2.5 if x[\"DBH\"]<=18 else 1,axis=1)\n",
    "\n",
    "natural = natural.groupby(\"species\")[[\"BA\",\"count\"]].sum()\n",
    "past = past.groupby(\"species\")[\"BA\"].agg([(\"BA\",\"sum\"),(\"count\",\"count\")])\n",
    "\n",
    "past[[\"BA\",\"density\"]],natural[[\"BA\",\"density\"]] =past[[\"BA\",\"count\"]]/df[\"area\"].sum(),natural[[\"BA\",\"count\"]]/natural_area\n",
    "\n",
    "#measuring total\n",
    "pba,nba = past[\"BA\"].sum(),natural[\"BA\"].sum()\n",
    "pdn,ndn = past[\"density\"].sum(),natural[\"density\"].sum()\n",
    "\n",
    "#extract dominant species only\n",
    "past.sort_values(\"BA\",ascending=False,inplace=True)\n",
    "natural.sort_values(\"BA\",ascending=False,inplace=True)\n",
    "pastdom,naturaldom = past.iloc[0:10,0],natural.iloc[0:10,0]\n",
    "lists = pastdom.index.tolist()+naturaldom.index.tolist()\n",
    "natural=natural[natural.index.isin(lists)]\n",
    "past=past[past.index.isin(lists)]\n",
    "\n",
    "\n",
    "otpba,otnba = pba-past[\"BA\"].sum(), nba-natural[\"BA\"].sum()\n",
    "otpdn,otndn = pdn-past[\"density\"].sum(),ndn-natural[\"density\"].sum()\n",
    "\n",
    "#calculate percentage and make dataframe\n",
    "past[[\"BA_%\",\"density_%\"]],natural[[\"BA_%\",\"density_%\"]] = round(past[[\"BA\",\"density\"]]*100/[pba,pdn],2),round(natural[[\"BA\",\"density\"]]*100/[nba,ndn],2)\n",
    "past[\"BA\"],natural[\"BA\"] = round(past[\"BA\"],2),round(natural[\"BA\"],2)\n",
    "past[\"density\"],natural[\"density\"] =round(past[\"density\"],2),round(natural[\"density\"],2)\n",
    "\n",
    "past=past[[\"BA\",\"BA_%\",\"density\",\"density_%\"]]\n",
    "natural=natural[[\"BA\",\"BA_%\",\"density\",\"density_%\"]]\n",
    "\n",
    "Ptype,Ntype = Past.drop_duplicates(\"species\")[[\"species\",\"type\"]],Natural.drop_duplicates(\"species\")[[\"species\",\"type\"]]\n",
    "\n",
    "totype = pd.concat([Ptype,Ntype],axis=0).reset_index().drop_duplicates(\"species\").drop(columns=[\"index\"])\n",
    "\n",
    "past,natural = pd.merge(past,totype,on=\"species\",how=\"left\"),pd.merge(natural,totype,on=\"species\",how=\"left\")\n",
    "past.set_index([\"type\",\"species\"],inplace=True)\n",
    "natural.set_index([\"type\",\"species\"],inplace=True)\n",
    "\n",
    "past.sort_index(level=0,inplace=True,ascending=False)\n",
    "natural.sort_index(level=0,inplace=True,ascending=False)\n",
    "\n",
    "#sort BA by type\n",
    "past = past.groupby(\"type\", group_keys=False).apply(lambda x: x.sort_values(\"BA\", ascending=False))\n",
    "natural = natural.groupby(\"type\", group_keys=False).apply(lambda x: x.sort_values(\"BA\", ascending=False))\n",
    "\n",
    "pastall=pd.DataFrame(columns=[\"BA\",\"BA_%\",\"density\",\"density_%\"],index=[[\"\",\"\"],[\"others\",\"total\"]],data=[[round(otpba,2),round(otpba*100/pba,2),round(otpdn,2),round(otpdn*100/pdn,2)],[round(pba,2),100.0,round(pdn,2),100.0]])\n",
    "naturalall=pd.DataFrame(columns=[\"BA\",\"BA_%\",\"density\",\"density_%\"],index=[[\"\",\"\"],[\"others\",\"total\"]],data=[[round(otnba,2),round(otnba*100/nba,2),round(otndn,2),round(otndn*100/ndn,2)],[round(nba,2),100.0,round(ndn,2),100.0]])\n",
    "\n",
    "past=pd.concat([past,pastall])\n",
    "past=past.reset_index()\n",
    "natural=pd.concat([natural,naturalall])\n",
    "natural=natural.reset_index()\n",
    "\n",
    "dom = pd.merge(past,natural,on=[\"level_0\",\"level_1\"],how=\"outer\",suffixes=(\"_past\",\"_current\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make NMDS dataframe (Fig2)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Past = pd.read_csv(\"./inventory_historical.csv\")\n",
    "past = Past.copy()\n",
    "Curr = pd.read_csv(\"./inventory_current.csv\")\n",
    "curr = Curr[Curr[\"forest_type\"]==\"natural\"]\n",
    "\n",
    "#select region (shikoku or kyushu)\n",
    "region=\"kyushu\"\n",
    "\n",
    "past = past[past[\"region\"]==region]\n",
    "curr = curr[curr[\"region\"]==region]\n",
    "\n",
    "past[\"BA\"] = ((past[\"DBH\"]/2)**2*math.pi)/10000\n",
    "curr[\"BA\"] = curr.apply(lambda x : ((x[\"DBH\"]/2)**2)/10000 if x[\"DBH\"]>=18 else ((x[\"DBH\"]/2)**2)/4000,axis=1)\n",
    "\n",
    "pdom = past.groupby(\"species\")[\"BA\"].sum().sort_values(ascending=False)/past[\"BA\"].sum()*100\n",
    "cdom = curr.groupby(\"species\")[\"BA\"].sum().sort_values(ascending=False)/curr[\"BA\"].sum()*100\n",
    "\n",
    "#extract dominant species (relative BA >= 1%)\n",
    "psp=pdom[pdom>=1]\n",
    "csp=cdom[cdom>=1]\n",
    "\n",
    "pastba=past.groupby([\"ID\",\"species\"])[\"BA\"].sum().reset_index()\n",
    "pastba=pastba.pivot(index=\"ID\",columns=\"species\",values=\"BA\").fillna(0)\n",
    "pastba=pastba[list(psp.index)]\n",
    "pastba=pd.merge(pd.DataFrame(index=pastba.index,columns=[\"group\"],data=[\"past\"]*len(pastba)),pastba,left_index=True,right_index=True)\n",
    "\n",
    "currba=curr.groupby([\"ID\",\"species\"])[\"BA\"].sum().reset_index()\n",
    "currba=currba.pivot(index=\"ID\",columns=\"species\",values=\"BA\").fillna(0)\n",
    "currba=currba[list(csp.index)]\n",
    "currba[\"group\"]=\"current\"\n",
    "\n",
    "nmds = pd.concat([pastba,currba],axis=0).fillna(0)\n",
    "\n",
    "#nmds is dataframe for NMDS analysis\n",
    "#NMDS analysis is performed in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FigS2 violinplot \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyfunc as pf\n",
    "\n",
    "past = pd.read_csv(\"./filelist_historical.csv\",index_col=0)\n",
    "curr = pd.read_csv(\"./filelist_current.csv\")\n",
    "\n",
    "past_k,past_s = past[past[\"region\"]==\"kyushu\"], past[past[\"region\"]==\"shikoku\"]\n",
    "curr_k,curr_s = curr[curr[\"region\"]==\"kyushu\"], curr[curr[\"region\"]==\"shikoku\"]\n",
    "\n",
    "past_k[\"forest_type\"],past_s[\"forest_type\"]=\"past\",\"past\"\n",
    "\n",
    "#ds and dk are also used GLM\n",
    "ds,dk=pd.concat([past_s, curr_s],axis=0), pd.concat([past_k,curr_k],axis=0)\n",
    "d= pd.concat([ds,dk],axis=0)\n",
    "\n",
    "sns.set_palette(\"tab10\")\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "dk.reset_index(drop=True,inplace=True)\n",
    "ds.reset_index(drop=True,inplace=True)\n",
    "ds.iloc[293,:],ds.iloc[296,:]=ds.iloc[296,:],ds.iloc[293,:]\n",
    "sns.violinplot(y=\"allC\",x=\"forest_type\",data=dk,ax=ax[1],density_norm=\"area\",bw_adjust=0.7,color=\"#bbbbbb\")\n",
    "sns.violinplot(y=\"allC\",x=\"forest_type\",data=ds,ax=ax[0],density_norm=\"area\",bw_adjust=0.7,color=\"#bbbbbb\")\n",
    "ax[0].set_ylim(0,370)\n",
    "ax[1].set_ylim(0,370)\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[1].set_xlabel(\"\")\n",
    "ax[0].set_xticklabels([\"past\",\"natural\",\"artificial\"],fontsize=20)\n",
    "ax[1].set_xticklabels([\"past\",\"natural\",\"artificial\"],fontsize=20)\n",
    "ax[0].set_yticklabels([0,50,100,150,200,250,300,350],fontsize=16)\n",
    "ax[1].set_yticklabels([0,50,100,150,200,250,300,350],fontsize=16)\n",
    "ax[0].set_ylabel(\"biomass (Mg C/ha)\",fontsize=20)\n",
    "ax[1].set_ylabel(\"\")\n",
    "ax[0].set_title(\"Shikoku\",fontsize=20)\n",
    "ax[1].set_title(\"Kyushu\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig1 and FigS4 DBH histgram\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Past = pd.read_csv(\"./inventory_historical.csv\")\n",
    "File= pd.read_csv(\"./filelist_historical.csv\")\n",
    "Curr = pd.read_csv(\"./inventory_current.csv\")\n",
    "\n",
    "past=Past.copy()\n",
    "file=File.copy()\n",
    "curr=Curr.copy()\n",
    "\n",
    "curr=curr[curr[\"forest_type\"]==\"natural\"]\n",
    "\n",
    "#select region (shikoku or kyushu)\n",
    "region=\"shikoku\"\n",
    "\n",
    "past = past[past[\"region\"]==region]\n",
    "curr = curr[curr[\"region\"]==region]\n",
    "file = file[file[\"region\"]==region]\n",
    "\n",
    "c_area = 0.1 * curr[\"ID\"].nunique()\n",
    "h_area = file[\"area\"].sum()\n",
    "\n",
    "#FigS4a\n",
    "#past=past[past[\"species\"].isin([\"Distylium racemosum\", \"Quercus salicina\"])]\n",
    "#curr=curr[curr[\"species\"].isin([\"Distylium racemosum\", \"Quercus salicina\"])]\n",
    "\n",
    "#FigS4b \n",
    "#past=past[past[\"species\"].isin([\"Quercus serrata\", \"Quercus mongolica\", \"Cerasus jamasakura\"])]\n",
    "#curr=curr[curr[\"species\"].isin([\"Quercus serrata\", \"Quercus mongolica\", \"Cerasus jamasakura\"])]\n",
    "\n",
    "c_EC,c_DB,c_EB = curr[curr[\"type\"]==\"EC\"],curr[curr[\"type\"]==\"DB\"],curr[curr[\"type\"]==\"EB\"]\n",
    "h_EC,h_DB,h_EB = past[past[\"type\"]==\"EC\"],past[past[\"type\"]==\"DB\"],past[past[\"type\"]==\"EB\"]\n",
    "\n",
    "c_list = [c_EC, c_DB, c_EB]\n",
    "h_list = [h_EC, h_DB, h_EB]\n",
    "\n",
    "for i,x in enumerate(c_list):\n",
    "    c_list[i]=x[[\"DBH\"]].dropna().values.flatten()\n",
    "for i,x in enumerate(h_list):\n",
    "    h_list[i]=x[[\"DBH\"]].dropna().values.flatten()\n",
    "\n",
    "\n",
    "bins=[2.5,7.5,12.5,17.5,18,22.5,27.5,32.5,37.5,42.5,47.5,52.5,57.5,62.5,67.5,72.5,77.5,82.5,87.5,92.5,97.5,102.5,107.5,112.5,117.5,122.5,127.5,132.5,137.5,142.5,147.5,152.5,157.5,162.5,167.5,172.5,177.5,182.5,187.5,192.5,197.5,202.5]\n",
    "\n",
    "fig,axes = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "counts_c, bins_c, _ = axes[0].hist([c_list[0],c_list[1],c_list[2]], stacked=True, range=[2.5, 202.5], bins=bins, alpha=0.7, label=[\"EC\",\"DB\",\"EB\"],log=True)\n",
    "counts_h, bins_h, _ = axes[1].hist([h_list[0],h_list[1],h_list[2]], stacked=True, range=[2.5, 202.5], bins=40, alpha=0.7, label=[\"EC\",\"DB\",\"EB\"],log=True)\n",
    "\n",
    "counts_c[:,[1,2,3]]=counts_c[:,[1,2,3]]*2.5\n",
    "counts_c[:,3]=counts_c[:,3]+counts_c[:,4]\n",
    "counts_c=np.delete(counts_c,4,1)\n",
    "\n",
    "counts_h_scaled = counts_h / h_area\n",
    "counts_c_scaled = counts_c / c_area\n",
    "counts_h_scaled= pf.log_ratio(counts_h_scaled,0.002,stack=True)\n",
    "counts_c_scaled= pf.log_ratio(counts_c_scaled,0.002,stack=True)\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"pastel\")\n",
    "fig,axes = plt.subplots(2,1,figsize=(6,12))\n",
    "\n",
    "datalist=[counts_h_scaled,counts_c_scaled]\n",
    "binlist=[bins_h,bins_h]\n",
    "name=[\"EC\",\"DB\",\"EB\"]\n",
    "\n",
    "for j,x in enumerate(datalist):\n",
    "    for i in range(len(x)):\n",
    "        axes[j].bar(binlist[j][:-1] ,x.iloc[i],align=\"edge\",width=np.diff(binlist[j]) ,bottom=x.iloc[:i].sum(),label=name[i],log=True)\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "ylab=axes[0].get_yticklabels()\n",
    "axes[0].set_ylabel(\"density (/ha ,log scale)\",fontsize=11)\n",
    "axes[0].set_xticklabels(np.arange(0,225,25),fontsize=12)\n",
    "axes[0].set_yticklabels(ylab,fontsize=12)\n",
    "axes[0].set_ylim(0.002,2000)\n",
    "axes[0].set_xlim(0,202.5)\n",
    "#axes[0].set_title(\"Historical\",fontsize=25)\n",
    "\n",
    "axes[1].set_xlabel(\"DBH (cm)\",fontsize=20)\n",
    "axes[1].set_ylabel(\"density (/ha ,log scale)\",fontsize=11)\n",
    "axes[1].set_xticklabels(np.arange(0,225,25),fontsize=12)\n",
    "axes[1].set_yticklabels(ylab,fontsize=12)\n",
    "axes[1].set_ylim(0.002,2000)\n",
    "axes[1].set_xlim(0,202.5)\n",
    "#axes[1].set_title(\"Current\",fontsize=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzing density of large-diameter trees by zero_inflated negative binomial GLM\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels as stm\n",
    "import seaborn as sns\n",
    "\n",
    "Past = pd.read_csv(\"./inventory_historical.csv\")\n",
    "pFile = pd.read_csv(\"./filelist_historical.csv\")\n",
    "Curr = pd.read_csv(\"./inventory_current.csv\")\n",
    "cFile = pd.read_csv(\"./filelist_current.csv\")\n",
    "\n",
    "past=Past.copy()\n",
    "pfile=pFile.copy()\n",
    "curr=Curr.copy()\n",
    "cfile = cFile.copy()\n",
    "\n",
    "curr = curr[curr[\"forest_type\"]==\"natural\"]\n",
    "cfile = cfile[cfile[\"forest_type\"]==\"natural\"]\n",
    "\n",
    "#select region (shikoku or kyushu)\n",
    "region=\"kyushu\"\n",
    "\n",
    "past = past[past[\"region\"]==region]\n",
    "curr = curr[curr[\"region\"]==region]\n",
    "pfile = pfile[pfile[\"region\"]==region]\n",
    "cfile = cfile[cfile[\"region\"]==region]\n",
    "\n",
    "past = past[past[\"DBH\"]>=50]\n",
    "curr = curr[curr[\"DBH\"]>=50]\n",
    "\n",
    "h_large = past.groupby(\"ID\")[\"DBH\"].count()\n",
    "h_large = pd.merge(h_large,pfile,on=\"ID\",how=\"outer\")\n",
    "h_large[\"dens\"] = h_large[\"DBH\"]/h_large[\"area\"]\n",
    "h_large[\"dens\"].fillna(0,inplace=True)\n",
    "h_large[\"historical\"] = 1\n",
    "h_large = h_large[[\"ID\", \"DBH\", \"dens\", \"historical\"]]\n",
    "\n",
    "c_large = pd.DataFrame(curr.groupby(\"ID\")[\"DBH\"].count())\n",
    "c_large = pd.merge(c_large,cfile,on=\"ID\",how=\"outer\")\n",
    "c_large[\"dens\"] = c_large[\"DBH\"]/0.1\n",
    "c_large[\"dens\"].fillna(0,inplace=True)\n",
    "c_large[\"historical\"] = 0\n",
    "\n",
    "larges = pd.concat([h_large,c_large],axis=0)\n",
    "\n",
    "h_ave, c_ave = larges[larges[\"historical\"]==1][\"dens\"].mean(), larges[larges[\"historical\"]==0][\"dens\"].mean()\n",
    "\n",
    "model=sm.ZeroInflatedNegativeBinomialP(endog=np.asarray(larges[\"dens\"]),exog=np.asarray(larges[\"historical\"]))\n",
    "result = model.fit(disp=0)\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLM(AGB)\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#use ds or dk (made in \"violin plot\" cell)\n",
    "data = ds #dk\n",
    "\n",
    "data[\"historical\"] = data.apply(lambda x : 1 if x[\"forest_type\"]==\"past\" else 0,axis=1)\n",
    "data[\"natural\"] = data.apply(lambda x : 1 if x[\"forest_type\"]==\"natural\" else 0,axis=1)\n",
    "\n",
    "formula = \"allC ~ historical + natural\"\n",
    "link = sm.families.links.log()\n",
    "model = smf.glm(formula, data=data , family=sm.families.Gamma(link=link))\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig3 taxonomic diversity (prepare iNEXT input file)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Past = pd.read_csv(\"./inventory_historical.csv\")\n",
    "Curr = pd.read_csv(\"./inventory_current.csv\")\n",
    "\n",
    "past = Past.copy()\n",
    "curr = Curr[Curr[\"forest_type\"]==\"natural\"]\n",
    "\n",
    "#select region (shikoku or kyushu)\n",
    "region=\"kyushu\"\n",
    "\n",
    "past = past[past[\"region\"]==region]\n",
    "curr = curr[curr[\"region\"]==region]\n",
    "\n",
    "curr[\"count\"] = curr.apply(lambda x : 2.5 if x[\"DBH\"]<=18 else 1,axis=1)\n",
    "\n",
    "#make iNEXT input file\n",
    "r_past,r_curr = past.groupby([\"ID\",\"species\"])[\"DBH\"].count().reset_index() ,curr.groupby([\"ID\",\"species\"])[\"count\"].count().reset_index()\n",
    "r_curr[\"count\"] = np.floor(r_curr[\"count\"])\n",
    "r_past,r_curr = r_past.pivot(index=\"species\",columns=\"ID\",values=\"DBH\"), r_curr.pivot(index=\"species\",columns=\"ID\",values=\"count\")\n",
    "\n",
    "rare=pd.concat([r_past,r_curr],axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fig3 FigS3 taxonomic diversity　(plot and GLM)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#read iNEXT output file (shikoku: inext_sresult.csv, kyushu: inext_kresult.csv)\n",
    "Data = pd.read_csv(\"./inext_kresult.csv\")\n",
    "File = pd.read_csv(\"./filelist_historical.csv\")\n",
    "\n",
    "data = Data.copy()\n",
    "file = File.copy()\n",
    "file[\"current\"] = 0\n",
    "\n",
    "#coverage: shikoku = 0.857, kyushu = 0.78\n",
    "datas = pd.merge(data,file,left_on = \"Cmax = 0.78\",right_on=\"ID\",how=\"left\")\n",
    "datas[\"area\"].fillna(0.1,inplace=True)\n",
    "datas[\"current\"].fillna(1,inplace=True)\n",
    "datas[\"current_a\"] = datas[\"current\"].replace({1:\"current\",0:\"historical\"})\n",
    "datas.rename(columns={\"q = 0\":\"diversity\"},inplace=True)\n",
    "\n",
    "#make model based on area-diversity relationship (GLM)\n",
    "data=datas[datas[\"current\"]==0]\n",
    "data[\"logarea\"] = np.log(data[\"area\"])\n",
    "formula = \"diversity ~ logarea\"\n",
    "link = sm.families.links.Log()\n",
    "model = smf.glm(formula, data=data , family=sm.families.Gamma(link=link))\n",
    "result = model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "#t_test\n",
    "from scipy import stats\n",
    "historical = datas[datas[\"current\"]==0][\"diversity\"]\n",
    "current = datas[datas[\"current\"]==1][\"diversity\"]\n",
    "t_stat, p_value = stats.ttest_ind(historical, current, equal_var=False)\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "#plot Fig3\n",
    "fig, ax = plt.subplots(1,2,figsize=(13.5,4.6))\n",
    "\n",
    "sns.boxplot(x=\"current\", y=\"diversity\", data=datas, palette=['#ffb482', '#a1c9f4'],ax=ax[0])\n",
    "\n",
    "ax[0].set_ylim(0,41)\n",
    "ax[0].set_ylabel(\"Taxonomic diversity\",fontsize=15)\n",
    "ax[0].set_xticklabels([\"historical\",\"current\"],fontsize=15)\n",
    "ax[0].set_xlabel(\"\")\n",
    "ax[0].set_yticks([0,10,20,30,40])\n",
    "ax[0].set_yticklabels([0,10,20,30,40],fontsize=15)\n",
    "plt.grid(False)\n",
    "\n",
    "\n",
    "#FigS3 scatter plot and model line\n",
    "#shikoku: 0.001-4.3, kyushu: 0.001-1.8\n",
    "x=pd.DataFrame(np.arange(0.001,1.8,0.001),columns=[\"area\"])\n",
    "sns.scatterplot(x=\"area\",y=\"diversity\", data=datas, hue=\"current_a\", palette=['#ff7f0e', '#1f77b4'],ax=ax[1])\n",
    "\n",
    "x[\"logarea\"] = np.log(x[\"area\"])\n",
    "x['y_pred'] = result.predict(x[\"logarea\"])\n",
    "\n",
    "data.sort_values(\"logarea\",inplace=True)\n",
    "\n",
    "handles, labels = ax[1].get_legend_handles_labels()\n",
    "ax[1].plot(x[\"area\"],x[\"y_pred\"],color=\"red\",linewidth=2)\n",
    "\n",
    "ax[1].set_ylim(0,41)\n",
    "ax[1].set_ylabel(\"Taxonomic diversity\",fontsize=15)\n",
    "ax[1].set_xlabel(\"area\",fontsize=15)\n",
    "ax[1].set_yticks([0,10,20,30,40])\n",
    "ax[1].set_yticklabels([0,10,20,30,40],fontsize=15)\n",
    "ax[1].legend(title=\"\",handles=handles ,fontsize=12,labels=[\"historical\",\"current\"])\n",
    "\n",
    "#shikoku ver.\n",
    "#ax[1].set_xticks([0,1,2,3,4])\n",
    "#ax[1].set_xticklabels([\"0\",\"1.0\",\"2.0\",\"3.0\",\"4.0\"],fontsize=15)\n",
    "#ax[1].text(0,35,\"Coverage=0.857\",fontsize=15)\n",
    "\n",
    "#kyushu ver.\n",
    "ax[1].text(0,35,\"Coverage=0.780\",fontsize=15)\n",
    "ax[1].set_xticks([0,0.5,1,1.5,2])\n",
    "ax[1].set_xticklabels([\"0\",\"0.5\",\"1.0\",\"1.5\",\"2.0\"],fontsize=15)\n",
    "\n",
    "#fig.savefig(\"./kyushu.png\",dpi=300,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical change of human impact and its effect on tree density (Fig4)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "Past = pd.read_csv(\"./inventory_historical.csv\")\n",
    "pFile = pd.read_csv(\"./filelist_historical.csv\")\n",
    "Curr = pd.read_csv(\"./inventory_current.csv\")\n",
    "cFile = pd.read_csv(\"./filelist_current.csv\")\n",
    "\n",
    "past=Past.copy()\n",
    "pfile=pFile.copy()\n",
    "curr=Curr.copy()\n",
    "cfile = cFile.copy()\n",
    "\n",
    "curr = curr[curr[\"forest_type\"]==\"natural\"]\n",
    "cfile = cfile[cfile[\"forest_type\"]==\"natural\"]\n",
    "\n",
    "#select region (shikoku or kyushu)\n",
    "region=\"kyushu\"\n",
    "\n",
    "past = past[past[\"region\"]==region]\n",
    "curr = curr[curr[\"region\"]==region]\n",
    "pfile = pfile[pfile[\"region\"]==region]\n",
    "cfile = cfile[cfile[\"region\"]==region]\n",
    "\n",
    "past = past[past[\"DBH\"]>=50]\n",
    "curr = curr[curr[\"DBH\"]>=50]\n",
    "\n",
    "h_large = past.groupby(\"ID\")[\"DBH\"].count()\n",
    "h_large = pd.merge(h_large,pfile,on=\"ID\",how=\"outer\")\n",
    "h_large[\"dens\"] = h_large[\"DBH\"]/h_large[\"area\"]\n",
    "h_large[\"dens\"].fillna(0,inplace=True)\n",
    "\n",
    "c_large = pd.DataFrame(curr.groupby(\"ID\")[\"DBH\"].count())\n",
    "c_large = pd.merge(c_large,cfile,on=\"ID\",how=\"outer\")\n",
    "c_large[\"dens\"] = c_large[\"DBH\"]/0.1\n",
    "c_large[\"dens\"].fillna(0,inplace=True)\n",
    "\n",
    "#distance from human structures (road, building) is calculated by QGIS\n",
    "h_large = pd.merge(h_large,hhuman,on=\"ID\",how=\"inner\")\n",
    "c_large = pd.merge(c_large,chuman,on=\"ID\",how=\"inner\")\n",
    "\n",
    "h_large = h_large[h_large[\"radius\"]<=1000]\n",
    "\n",
    "#add 1 if distance is 0\n",
    "h_large[\"log1900_dist\"]= np.log(h_large[\"1900_dist\"].replace(0,1))\n",
    "h_large[\"log1950_dist\"]= np.log(h_large[\"1950_dist\"].replace(0,1))\n",
    "c_large[\"logdist\"]= np.log(c_large[\"distance\"].replace(0,1))\n",
    "h_large[\"logdens\"] = np.log(c_large[\"dens\"].replace(0,1))  \n",
    "c_large[\"logdens\"] = np.log(c_large[\"dens\"].replace(0,1))  \n",
    "\n",
    "model = smf.glm(formula=\"big ~ log1900_dist\", data=h_large, family=sm.families.Poisson(link=sm.families.links.log()), offset=np.log(h_large[\"area\"]))\n",
    "model2 = smf.glm(formula=\"big ~ log1950_dist\", data=h_large, family=sm.families.Poisson(link=sm.families.links.log()), offset=np.log(h_large[\"area\"]))\n",
    "model3 = smf.glm(formula=\"big ~ logdist\", data=c_large, family=sm.families.Poisson(link=sm.families.links.log()), offset=np.log(0.1))\n",
    "\n",
    "result = model.fit()\n",
    "result2 = model2.fit()\n",
    "result3 = model3.fit()\n",
    "\n",
    "print(result.summary())\n",
    "print(result2.summary())\n",
    "print(result3.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
